---
layout: post
title: Blog Post 2
---

In this Blog Post, I’ll use webscraping to answer the following question:

> What movie or TV shows share actors with your favorite movie or show?

The idea of this question is that, if TV show Y has many of the same actors as TV show X, and I like X, I might also enjoy Y.

This post has two parts. In the first, larger part, I’ll write a webscraper for finding shared actors on IMDB. In the second, smaller part, I’ll use the results from your scraper to make recommendations.

The repository for this blog post is here: [Blog Post 2](https://github.com/lchen777-cl/Blog-Post-)

## Preparation

### Locate the Starting IMDB Page

I pick my favorite movie *The Comformist*. Its IMDB page is at: https://www.imdb.com/title/tt0065571/

Save this URL for a moment.

### Dry-Run Navigation

Now, we’re just going to practice clicking through the navigation steps that our scraper will take.

First, click on the Cast & Crew link. This will take you to a page with URL of the form https://www.imdb.com/title/tt0065571/fullcredits/

Next, scroll until you see the Series Cast section. Click on the portrait of one of the actors. This will take you to a page with a different-looking URL. For example, the URL for Avery Brooks, star of DS9, ishttps://www.imdb.com/name/nm0004462/

Finally, scroll down until you see the actor’s Filmography section. Note the titles of a few movies and TV shows in this section.

Our scraper is going to replicate this process. Starting with your favorite movie or TV show, it’s going to look at all the actors in that movie or TV show, and then log all the other movies or TV shows that they worked on.

### Initialize My Project

1. Create a new GitHub repository, and sync it with GitHub Desktop. This repository will house my scraper. The repository for this blog post is here: [Blog Post 2](https://github.com/lchen777-cl/Blog-Post-)

2. Open a terminal in the location of my repository on my laptop, and type:
```console
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```

### Tweak Settings

For now, add the following line to the file settings.py:
```python
CLOSESPIDER_PAGECOUNT = 20
```
This line just prevents my scraper from downloading too much data while you’re still testing things out. I’ll remove this line later.

## §1. Write My Scraper

Create a file inside the spiders directory called imdb_spider.py. Add the following lines to the file:
```python
import scrapy

class ImdbSpider(scrapy.Spider):

  name = 'imdb_spider'
  
  #our starting page
  start_urls = ['https://www.imdb.com/title/tt0065571/']
```

To write the scraper, we need to implement three parsing methods for the ImdbSpider class.

1. parse(self, response) should assume that you start on a movie page, and then navigate to the Cast & Crew page. Remember that this page has url <movie_url>fullcredits. Once there, the parse_full_credits(self,response) should be called, by specifying this method in the callback argument to a yielded scrapy.Request. The parse() method does not return any data.
```python
  def parse(self, response):
  """
  Assume that we start on a movie page, and then navigate to the Cast & Crew page
  """
    # get the link for Cast & Crew page
    link = 'https://www.imdb.com/title/tt0065571/fullcredits/'
    #link = str(self.start_urls[0]) + 'fullcredits/'
    # go to the Cast & Crew page and call parse_full_credits
    yield scrapy.Request(link, callback = self.parse_full_credits)
```

2. parse_full_credits(self, response) should assume that you start on the Cast & Crew page. Its purpose is to yield a scrapy.Request for the page of each actor listed on the page. Crew members are not included. The yielded request should specify the method parse_actor_page(self, response) should be called when the actor’s page is reached. The parse_full_credits() method does not return any data.

```python
  def parse_full_credits(self, response):
  """
  Assume that we start on the Cast & Crew page.
  Its purpose is to yield a scrapy.Request for the page of each actor listed on the page.
  """
     # get a list of relaive paths for each actor
    cast = [a.attrib["href"] for a in response.css("td.primary_photo a")]
    # loop through the list to enter each actor path and call parse_actor_page
    for actor in cast:
      yield scrapy.Request('https://www.imdb.com' + str(actor), callback = self.parse_actor_page)
```

3. parse_actor_page(self, response) should assume that you start on the page of an actor. It should yield a dictionary with two key-value pairs, of the form {"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}. The method should yield one such dictionary for each of the movies or TV shows on which that actor has worked. Note that you will need to determine both the name of the actor and the name of each movie or TV show. 

I use inspect the element to check the HTML code of the generate the command I want and run the scrapy shell in the command to make sure the data I scrape is correct.

```python
  def parse_actor_page(self, response):
  """
  Assume that we start on the page of an actor. 
  It should yield a dictionary with two key-value pairs of the form {"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}
  """
    # get actor name
    actor_name = response.css('span.itemprop::text').get()
    # get movies list
    movies_list = response.css('div.filmo-row').css('a::text').getall()
    # remove specific episode
    movies = [x for x in movies_list if not x.startswith('Episode')]
    # yield our data
    for x in movies:
      yield{
          "actor" : actor_name,
          "movie" : x
         }
```

Once your spider is fully written, comment out the line in the settings.py file.
```python
CLOSESPIDER_PAGECOUNT = 20
```

Then run the following command save a CSV file called movies.csv, with columns for actor names and the movies and TV shows on which they worked.
```console
scrapy crawl imdb_spider -o movies.csv
```

## §2. Make My Recommendations

In this session I will generate a table and graph of the recommended movies based on the data I scrape.

First, let's import the modules we need.
```python
import matplotlib.pyplot as plt
import pandas as pd 
import numpy as np
```

Then let's import the data.
```python
data = pd.read_csv("movies.csv")
```

Let's take a look at the data we obtained.

```python
data.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>actor</th>
      <th>movie</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Claudio Cappeli</td>
      <td>The Conformist</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Romano Costa</td>
      <td>The Conformist</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Romano Costa</td>
      <td>Amore e rabbia</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Romano Costa</td>
      <td>Partner</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Marilyn Goldin</td>
      <td>The Triumph of Love</td>
    </tr>
  </tbody>
</table>
</div>

Let's count the number of appearance of each movie and change the column names.

```python
count = data['movie'].value_counts().reindex()
count = pd.DataFrame(count)
count.index.name = 'movies'
count.reset_index(inplace=True)
count = count.rename(columns = {'movie':'number of shared actors'})
count.head(11)
```
Now we get the movies recommendation list as followed:

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movies</th>
      <th>number of shared actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The Conformist</td>
      <td>33</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Show all 6 episodes</td>
      <td>9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>post-production</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>In the Shadow of the Blue Rascal</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Partner</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Tropici</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Violent Naples</td>
      <td>5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Visa de censure n°X</td>
      <td>5</td>
    </tr>
    <tr>
      <th>8</th>
      <td>completed</td>
      <td>5</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Show all 8 episodes</td>
      <td>5</td>
    </tr>
    <tr>
      <th>10</th>
      <td>The Sun</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>

Apparently, some rows like "post-production" and "Show all episodes" are not movies. Let's drop all those column and check what movies have more than 5 shared actors.

```python
rec = count.loc[count['number of shared actors'] >= 5]
rec = rec.drop([1, 2, 8, 9])
rec
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movies</th>
      <th>number of shared actors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The Conformist</td>
      <td>33</td>
    </tr>
    <tr>
      <th>3</th>
      <td>In the Shadow of the Blue Rascal</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Partner</td>
      <td>6</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Tropici</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Violent Naples</td>
      <td>5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Visa de censure n°X</td>
      <td>5</td>
    </tr>
    <tr>
      <th>10</th>
      <td>The Sun</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>

Here's the movie recommendation list we want. Let's also visualize the result.

```python
import plotly.express as px
fig = px.histogram(rec[1:], x='movies', y='number of shared actors', title = 'Movies for you based on ' + rec["movies"][0])
fig.show()
```

![image-example.png]({{ site.baseurl }}/images/blogpost3.png)

Because I chose an Italian old movie, the result is not that desireable, but I still get some new movies that I might like to watch.







