---
layout: post
title: Blog Post 5
---

In this blog post, I will learn several new skills and concepts related to image classification in Tensorflow.

- Tensorflow `Datasets` provide a convenient way for us to organize operations on our training, validation, and test data sets.
- *Data augmentation* allows us to create expanded versions of our data sets that allow models to learn patterns more robustly.
Transfer learning allows us to use pre-trained models for new tasks.

We will work Google Colab. When training models, enabling a GPU runtime (under Runtime -> Change Runtime Type) is likely to lead to significant speed benefits. [Here's the code for this post.](https://colab.research.google.com/drive/1VWCiNE65HkORyfY46KCOjG5zj5saiNXV#scrollTo=E4nitgh7FZ1R)

### Goal
Can you teach a machine learning algorithm to distinguish between pictures of dogs and pictures of cats?
We will consider a setting in which we have only one image for pet. Can we reliably distinguish between cats and dogs in this case?

### Acknowledgment
Major parts of this Blog Post assignment, including several code chunks, are based on the [TensorFlow Transfer Learning Tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning). 

## §1. Load Packages and Obtain Data

###Preparation

First let's load the packages.
```python
import os
from tensorflow.keras import utils 
import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
```

We will use a dataset containing several thousand images of cats and dogs. Let's download and extract a zip file containing the images, and consturct the training and validation datasets using a special-purpose `keras` utility called `image_dataset_from_directory`.
```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.

We can see that we have 2000 imgaes for the train dataset and 1000 imgaes for the validation dataset. We have only 2 classes — cat and dog.

Now we include the following code to help us read data faster.

```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```
### Working with Datasets

Everytime we call `train_dataset.take(1)` we can retrieve one batch, for our case are labeled 32 imagies from the dataset. Now to try out working with the dataset, let's write a function generating three random picutres of cats and three random pictures of dogs.

```python
# Working with Datasets
plt.figure(figsize=(10, 10))
class_names = ['cats', 'dogs']
# define the function
def cats_and_dogs():
	""""
	shows labeled images of cats in one row and labeled images of dogs in another row
	"""""
    for images, labels in train_dataset.take(1):
        i = 1
        for j in range(len(labels)):
            if labels[j]==0 and i < 4:
              ax = plt.subplot(2, 3, i)
              i = i+1
              plt.imshow(images[j].numpy().astype("uint8"))
              plt.title(class_names[labels[j]])
              plt.axis("off")
        for j in range(len(labels)):
            if labels[j]==1 and i < 7:
              ax = plt.subplot(2, 3, i)
              i = i+1
              plt.imshow(images[j].numpy().astype("uint8"))
              plt.title(class_names[labels[j]])
              plt.axis("off")
# call the function
cats_and_dogs()
```

![image-example.png]({{ site.baseurl }}/images/bp51.png)

### Check Label Frequencies
Now let's try to work with labels. We first creates a label iterator.


```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
```

With the label iterator, we can count the number of pictures of dogs and cats and check what is the probability we get a picture of dog.

```python
dog = 0
cat = 0
for x in labels_iterator:
  if x == 1:
    dog = dog + 1
  else:
    cat = cat +1
print(cat, dog)
```

    1000 1000

We see that in the training dataset, half of the images are cats and the other half are dogs. Therefore, the probability **50%** we should improve on.


## §2. Basic Model

We first check on the size of the image.
```python
for images, labels in train_dataset.take(1):
  print(images[1].shape)
```

    (160, 160, 3)

Now we're going to create a tf.keras.Sequential model using some of the layers. To achieve a better accuracy, I try to add more `Conv2D` and `MaxPooling2D` layers, but it won't work. I also add and delete a dense layer `layers.Dense(320, activation='relu')`from the sequential.

```python
#First Model
model1 = tf.keras.Sequential([
    layers.Conv2D(160, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(160, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(320, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(.5),
    layers.Dense(2),
])
```

We compile the model and obtain the history date using the following code.
```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset
)
```

Let's check on the learning curve.
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```
![image-example.png]({{ site.baseurl }}/images/bp52.png)

- The accuracy of this model stabilized between **55%** and **60%** during training.
- We are now 5~10% better than the baseline.
- We observe a overfitting with the training dataset. In theory, dropout layer can prevent the model from overfitting but it doesn't work in this basic model.

## §2. Model with Data Augmentation

Now we’re adding some data augmentation layers to your model. By using data augmentation, we apply random transformations to the images, introducing diversity to the large dataset. This method could help us reduce overfitting.

### Work with Data Augmentation

We try to apply data augmentation to the training image to see its effects.

```python
#Model with Data Augementation
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip('horizontal'),
  tf.keras.layers.RandomRotation(0.2),
])
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  first_image = image[0]
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
    plt.imshow(augmented_image[0] / 255)
    plt.axis('off')
```

![image-example.png]({{ site.baseurl }}/images/bp53.png)

Here we get nine pictures of a cut cat's head with different angels.

### Model

In our model, we add rotation and horizontal flipping layers.

```python
#Second Model
model2 = tf.keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.2),
    layers.Conv2D(160, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(160, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(320, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(.5),
    layers.Dense(2),
])
```

We train the model and visualize the the training history.
```python
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```
![image-example.png]({{ site.baseurl }}/images/bp54.png)

- The accuracy of this model stabilized between **60%** and **65%** during training.
- We are now 10~15% better than the baseline.
- We observe no overfitting, which proves that data agumentation does reduce overfitting.

## §4. Data Preprocessing

Data preprocessing refer to manipulation or dropping of data before it is used in order to ensure or enhance performance. In our case, we normalize RGB values between 0 and 1, or possibly between -1 and 1.

We craete a preprocessing layer called `preprocessor` with the following code:

```python
#Third model
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Now let's add the layer to our model. To increase the accuracy, I add an extra `Conv2D` and `MaxPooling2D` layers.

```python
model3 = tf.keras.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.2),
    layers.Conv2D(160, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(160, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(320, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(320, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dropout(.5),
    layers.Dense(2),
])
```

Let's train the model and check the accuracy.


```python
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![image-example.png]({{ site.baseurl }}/images/bp55.png)

- The accuracy of this model stabilized between **70%** and **80%** during training.
- We are now 20~30% better than the baseline.
- There may be overfitting during the training process but an accuracy of 80% with training data is acceptab;e.

## §5. Transfer Learning

There's a simple easy way to improve the model accuracy - learn from other's training models. To achieve this, we access a pre-existing base model and incorporate it to our model.

For this image classification task, we download `MobileNetV2` and configure it as a layer.

```python
#Fourth model
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Then we include it in our own model. 

```python
model4 = tf.keras.Sequential([
    preprocessor,
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.2),
    base_model_layer,
    layers.GlobalMaxPool2D(),
    layers.Dropout(.2),
    layers.Dense(2)
])
```

Notice that I reduce the number of layers used because the base model has already done a lot for us. We can check the composition of tihis model in summary.

```python
model4.summary()
```

	Model: "sequential"
	_________________________________________________________________
	 Layer (type)                Output Shape              Param #   
	=================================================================
	 model_1 (Functional)        (None, 160, 160, 3)       0         
	                                                                 
	 random_flip (RandomFlip)    (None, 160, 160, 3)       0         
	                                                                 
	 random_rotation (RandomRota  (None, 160, 160, 3)      0         
	 tion)                                                           
	                                                                 
	 model (Functional)          (None, 5, 5, 1280)        2257984   
	                                                                 
	 global_max_pooling2d (Globa  (None, 1280)             0         
	 lMaxPooling2D)                                                  
	                                                                 
	 dropout (Dropout)           (None, 1280)              0         
	                                                                 
	 dense (Dense)               (None, 2)                 2562      
	                                                                 
	=================================================================
	Total params: 2,260,546
	Trainable params: 2,562
	Non-trainable params: 2,257,984
	_________________________________________________________________

We have 2,257,984 parameters in total to train the base model and our model takes a total parameters of 2,260,546. If we check on the summary of the base model, it can go forever. 

Let's train the model and see how it performs.

```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

```python
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```
![image-example.png]({{ site.baseurl }}/images/bp56.png)

- The accuracy of this model stabilized between **95%** and **99%** during training.
- We are now 45~49% better than the baseline, even almost achieve 100%.
- We observe no overfitting with the training dataset. In fact, the validation accuracy is even higher than the training accuracy.

## §6. Score on Test Data

Let's apply the model4 to test data to see its performance.

```python
loss, accuracy = model4.evaluate(test_dataset)
print('Test accuracy :', accuracy)
```
    6/6 [==============================] - 1s 61ms/step - loss: 0.0492 - accuracy: 0.9896
    Test accuracy : 0.9895833134651184

Finally, we can achieve an almost 99% accuracy on test data. We go a long way from the base line 50% and the final result 99% and learn a lot about the neural network and tensorflow applied in image classification.
